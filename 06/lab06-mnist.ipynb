{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadania - klasyfikacja wieloklasowa\n",
    "\n",
    "Celem zadań jest zbudowanie klasyfikatora rozpoznającego ręcznie zapisaną cyfrę 0-9 z pojedynczego czarno-białego obrazu. Zestaw danych, na których będziemy pracować to MNIST (https://en.wikipedia.org/wiki/MNIST_database).\n",
    "\n",
    "MNIST zawiera ok. 70000 obrazów, każdy oznaczony cyfrą, którą przedstawia. Pojedyncze obrazy w tym zbiorze danych wyglądają np. tak: \n",
    "\n",
    "<img src=\"http://pavel.surmenok.com/wp-content/uploads/2014/07/mnistdigits.gif\"/>\n",
    "\n",
    "Zbiór jest już podzielony na zestawy treningowy i testowy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "Pobierz cztery pliki `*-images-idx3-ubyte.gz` ze strony http://yann.lecun.com/exdb/mnist/ i rozpakuj (!) w tym samym katalogu, w którym znajduje się notatnik (pod Linuxem możesz wykorzystać skrypt `download.sh`). **Uwaga**: proszę nie wrzucać tych plików do swojego repozytorium.\n",
    "\n",
    "1. Wyświetl w postaci tablicy oraz w postaci obrazka pierwsze pięć liczb. Wykorzystaj do tego funkcje `readMnist` i `showImage` (nie jest potrzebna znajomość ich działania).\n",
    "1. Stwórz macierze dla zestawów treningowego i testowego, zawierające pierwsze 1000 obrazków każdy (wykorzystaj `maxItems` w funkcji `mnistMatrix`, podanie `maxItems=60000` wczyta wszystkie dane). Odpowiedz na pytania: ile cech ma każdy obrazek? Czym są te cechy? Jak przedstawione są etykiety w zbiorze testowym?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna\n",
    "\n",
    "1. Na podstawie materiałów z wykładu nr 5 zbuduj model wieloklasowej regresji logistycznej rozpoznający wszystkie 10 cyfr na podstawie pierwszych 1000 danych. Eksperymentuj z doborem parametrów w algorytmie GD. Uwaga: należy rozpocząć od małej liczby kroków, np. 100, i powoli zwiększać. Jaką osiągnięto poprawność (_accuracy_)?\n",
    "1. Zwiększ liczbę danych treningowych do 10000, 20000 itd. Co się dzieje z algorytmem GD?\n",
    "1. Zaimplementuj algorytm Batch-SGD (_Batch Stochastic Gradient Descent_), którego wykrzystasz w miejsce podstawowego algorytmu. Różnice między tymi algorytmami obrazują poniższe pseudokody:\n",
    "\n",
    "   Gradient Descent\n",
    "   ```\n",
    "   for i in range(num_epochs):\n",
    "       gradient = evaluate_gradient(J, data, thetas)\n",
    "       thetas = thetas - alpha * gradient\n",
    "   ```\n",
    "   \n",
    "   Batch Stochastic Gradient Descent\n",
    "   ```\n",
    "   for i in range(num_epochs):\n",
    "       shuffle(data)\n",
    "       for batch in get_batch(data, batch_size=50):\n",
    "           gradient = evaluate_gradient(J, batch, thetas)\n",
    "           thetas = thetas - alpha * gradient\n",
    "    ```\n",
    "    \n",
    "    Gdzie `num_epochs` to liczba epok, a epoką nazywamy jednokrotne wykorzystanie wszystkich danych w zbiorze treningowym do nauki parametrów (do tej pory zakładaliśmy `num_epoch=1`).\n",
    "\n",
    "1. Wykorzystaj Batch-SGD do zbudowania modelu na całosci danych treningowych (można zastosować jedną epokę i pominąć randomizację dla uzyskania stabilnych wyników). Jaką osiągnięto poprawność, dopasowując parametry `alpha`, `maxSteps` i `batchSize`? Zmiana których parametrów ma najmniejszy/największy wpływ na osiągany wynik? Które parametry są łatwe/trudne do dopasowywania?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def readMnist(dataset = \"training\", path = \".\"):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_img(i)\n",
    "\n",
    "def showImage(image):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 2D array of pixel data.\n",
    "    \"\"\"\n",
    "    from matplotlib import pyplot\n",
    "    import matplotlib as mpl\n",
    "    fig = pyplot.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mnistMatrix(data, maxItems=1000):\n",
    "    datalist = [t for t in data]\n",
    "    m = maxItems\n",
    "    n = 28 * 28 + 1\n",
    "    X = np.matrix(np.zeros(m * n)).reshape(m, n)\n",
    "    Y = np.matrix(np.zeros(m)).reshape(m, 1)\n",
    "    for i, (label, image) in enumerate(datalist[:m]):\n",
    "        X[i, 0] = 1 # bias term\n",
    "        X[i, 1:] = image.reshape(28*28,)\n",
    "        Y[i] = label\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]]\n",
      "[[ 5.]\n",
      " [ 0.]\n",
      " [ 4.]\n",
      " [ 1.]\n",
      " [ 9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAAD7CAYAAAD0IbP6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6Ypf5S3jC9QyvkAt4wvUMr5ALfP/WkxyhjSRfOAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18400f40e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n"
     ]
    }
   ],
   "source": [
    "X, y = mnistMatrix(readMnist(), maxItems=60000)\n",
    "X_test, y_test = mnistMatrix(readMnist(dataset='testing'), maxItems=60000)\n",
    "\n",
    "print(X[:5])\n",
    "print(y[:5])\n",
    "showImage(X[:5, 1:].reshape(5*28, 28))\n",
    "\n",
    "print(np.size(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Każdy obrazek złożony jest z 785 cech, które wszystkie oprócz pierwszej (równej 1) są pikselami danego obrazka, a wartość cechy oznacza kolor, 0 - biały, 255 - czarny. Etykiety przedstawione są w postaci liczb całkowitych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    X[:,1:] = X[:,1:] / 255\n",
    "    return X\n",
    "\n",
    "def mapY(y, cls):\n",
    "    m = len(y)\n",
    "    yBi = np.matrix(np.zeros(m)).reshape(m, 1)\n",
    "    yBi[y == cls] = 1.\n",
    "    return yBi\n",
    "\n",
    "def indicatorMatrix(y):\n",
    "    classes = np.unique(y.tolist())\n",
    "    m = len(y)\n",
    "    k = len(classes)\n",
    "    Y = np.matrix(np.zeros((m, k)))\n",
    "    for i, cls in enumerate(classes):\n",
    "        Y[:,i] = mapY(y, cls)\n",
    "    return Y\n",
    "\n",
    "def h(theta, X):\n",
    "    return 1.0/(1.0 + np.exp(-X*theta))\n",
    "\n",
    "def J(h, theta, X, y):\n",
    "    m = len(y)\n",
    "    h_val = h(theta,X)\n",
    "    s1 = np.multiply(y, np.log(h_val))\n",
    "    s2 = np.multiply((1 - y), np.log(1 - h_val))\n",
    "    return -np.sum(s1 + s2, axis=0) / m\n",
    "\n",
    "def dJ(h,theta,X,y):\n",
    "    return 1.0/len(y)*(X.T*(h(theta,X)-y))\n",
    "\n",
    "def GD(h, fJ, fdJ, theta, X, y, alpha=0.01, eps=10**-3, maxSteps=10000):\n",
    "    errorCurr = fJ(h, theta, X, y)\n",
    "    errors = [[errorCurr, theta]]\n",
    "    while True:\n",
    "        # oblicz nowe theta\n",
    "        theta = theta - alpha * fdJ(h, theta, X, y)\n",
    "        # raportuj poziom błędu\n",
    "        errorCurr, errorPrev = fJ(h, theta, X, y), errorCurr\n",
    "        # kryteria stopu\n",
    "        if abs(errorPrev - errorCurr) <= eps:\n",
    "            break\n",
    "        if len(errors) > maxSteps:\n",
    "            break\n",
    "        errors.append([errorCurr, theta]) \n",
    "    return theta, errors\n",
    "\n",
    "def classify(thetas, X, debug=False):\n",
    "    regs = np.array([(X*theta).item() for theta in thetas])\n",
    "    if debug:\n",
    "        print(\"regs  =\", regs)\n",
    "    probs = softmax(regs)\n",
    "    if debug:\n",
    "        print(\"probs =\", np.around(probs,decimals=3))\n",
    "    return np.argmax(probs), probs\n",
    "\n",
    "def trainMaxEnt(X, Y, steps):\n",
    "    n = X.shape[1]\n",
    "    thetas = []\n",
    "    for c in range(Y.shape[1]):\n",
    "        YBi = Y[:,c]\n",
    "        theta = np.matrix(np.zeros(n)).reshape(n,1)\n",
    "        thetaBest, errors = GD(h, J, dJ, theta, \n",
    "                               X, YBi, alpha=0.1, eps=10**-4, maxSteps=steps)\n",
    "        thetas.append(thetaBest)\n",
    "    return thetas\n",
    "\n",
    "def softmax(X):\n",
    "    return np.exp(X) / np.sum(np.exp(X))\n",
    "\n",
    "def calculateAcc(thetas, X_test, y_test):\n",
    "    acc = 0.0\n",
    "    for i in range(len(y_test)):\n",
    "        cls, probs = classify(thetas, X_test[i])\n",
    "        correctCls = int(y_test[i].item())\n",
    "        if i < 6:\n",
    "            print(correctCls, \"  <=>\", cls, \" -- \", cls == correctCls, np.round(probs, 4).tolist())\n",
    "        acc += correctCls == cls\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_norm = normalize(X)\n",
    "X_test_norm = normalize(X_test)\n",
    "ind_y = indicatorMatrix(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7   <=> 7  --  True [0.0032, 0.0004, 0.0042, 0.0073, 0.004, 0.0025, 0.0005, 0.9618, 0.0034, 0.0128]\n",
      "2   <=> 6  --  False [0.1519, 0.0253, 0.2105, 0.0561, 0.0012, 0.2272, 0.2419, 0.0008, 0.0818, 0.0034]\n",
      "1   <=> 1  --  True [0.0043, 0.8562, 0.0309, 0.0174, 0.0056, 0.0119, 0.0164, 0.0227, 0.0221, 0.0125]\n",
      "0   <=> 0  --  True [0.9327, 0.0001, 0.0043, 0.0008, 0.0006, 0.0114, 0.0367, 0.0108, 0.0012, 0.0014]\n",
      "4   <=> 4  --  True [0.0131, 0.0012, 0.0612, 0.0098, 0.7767, 0.0078, 0.0241, 0.0527, 0.0192, 0.0342]\n",
      "1   <=> 1  --  True [0.0011, 0.9273, 0.0133, 0.0088, 0.002, 0.0047, 0.003, 0.0174, 0.0133, 0.009]\n",
      "\n",
      "Accuracy = 0.772\n",
      "7   <=> 7  --  True [0.0008, 0.0, 0.0014, 0.0026, 0.0004, 0.0003, 0.0, 0.992, 0.0006, 0.0017]\n",
      "2   <=> 6  --  False [0.1438, 0.0086, 0.2102, 0.0375, 0.0001, 0.1991, 0.3421, 0.0001, 0.0575, 0.0009]\n",
      "1   <=> 1  --  True [0.0011, 0.9373, 0.0175, 0.0069, 0.0017, 0.0027, 0.0076, 0.0123, 0.0085, 0.0045]\n",
      "0   <=> 0  --  True [0.9829, 0.0, 0.0008, 0.0, 0.0, 0.0027, 0.0101, 0.0032, 0.0001, 0.0001]\n",
      "4   <=> 4  --  True [0.0036, 0.0003, 0.0233, 0.0021, 0.9096, 0.0013, 0.0101, 0.0235, 0.0114, 0.0149]\n",
      "1   <=> 1  --  True [0.0002, 0.9681, 0.0069, 0.0032, 0.0005, 0.0008, 0.0009, 0.0109, 0.0051, 0.0034]\n",
      "\n",
      "Accuracy = 0.812\n",
      "7   <=> 7  --  True [0.0008, 0.0, 0.0014, 0.0026, 0.0004, 0.0003, 0.0, 0.992, 0.0006, 0.0017]\n",
      "2   <=> 6  --  False [0.1438, 0.0086, 0.2102, 0.0375, 0.0001, 0.1991, 0.3421, 0.0001, 0.0575, 0.0009]\n",
      "1   <=> 1  --  True [0.0011, 0.9373, 0.0175, 0.0069, 0.0017, 0.0027, 0.0076, 0.0123, 0.0085, 0.0045]\n",
      "0   <=> 0  --  True [0.9829, 0.0, 0.0008, 0.0, 0.0, 0.0027, 0.0101, 0.0032, 0.0001, 0.0001]\n",
      "4   <=> 4  --  True [0.0036, 0.0003, 0.0233, 0.0021, 0.9096, 0.0013, 0.0101, 0.0235, 0.0114, 0.0149]\n",
      "1   <=> 1  --  True [0.0002, 0.9681, 0.0069, 0.0032, 0.0005, 0.0008, 0.0009, 0.0109, 0.0051, 0.0034]\n",
      "\n",
      "Accuracy = 0.812\n"
     ]
    }
   ],
   "source": [
    "thetas_100 = trainMaxEnt(X_norm[:1000], ind_y[:1000], 100)\n",
    "print(\"\\nAccuracy =\", calculateAcc(thetas_100, X_test_norm[:1000], y_test[:1000])/len(X_test_norm[:1000]))\n",
    "\n",
    "thetas_1000 = trainMaxEnt(X_norm[:1000], ind_y[:1000], 1000)\n",
    "print(\"\\nAccuracy =\", calculateAcc(thetas_1000, X_test_norm[:1000], y_test[:1000])/len(X_test_norm[:1000]))\n",
    "\n",
    "thetas_2000 = trainMaxEnt(X_norm[:1000], ind_y[:1000], 5000)\n",
    "print(\"\\nAccuracy =\", calculateAcc(thetas_2000, X_test_norm[:1000], y_test[:1000])/len(X_test_norm[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla 100 kroków accuracy wyniosło 0.772, dla 1000 - 0.812, dla 5000 również 0.812\n",
    "Co w przypadku 10000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7   <=> 7  --  True [0.0008, 0.0, 0.0014, 0.0026, 0.0004, 0.0003, 0.0, 0.992, 0.0006, 0.0017]\n",
      "2   <=> 6  --  False [0.1438, 0.0086, 0.2102, 0.0375, 0.0001, 0.1991, 0.3421, 0.0001, 0.0575, 0.0009]\n",
      "1   <=> 1  --  True [0.0011, 0.9373, 0.0175, 0.0069, 0.0017, 0.0027, 0.0076, 0.0123, 0.0085, 0.0045]\n",
      "0   <=> 0  --  True [0.9829, 0.0, 0.0008, 0.0, 0.0, 0.0027, 0.0101, 0.0032, 0.0001, 0.0001]\n",
      "4   <=> 4  --  True [0.0036, 0.0003, 0.0233, 0.0021, 0.9096, 0.0013, 0.0101, 0.0235, 0.0114, 0.0149]\n",
      "1   <=> 1  --  True [0.0002, 0.9681, 0.0069, 0.0032, 0.0005, 0.0008, 0.0009, 0.0109, 0.0051, 0.0034]\n",
      "\n",
      "Accuracy = 0.812\n",
      "7   <=> 7  --  True [0.0008, 0.0, 0.0014, 0.0026, 0.0004, 0.0003, 0.0, 0.992, 0.0006, 0.0017]\n",
      "2   <=> 6  --  False [0.1438, 0.0086, 0.2102, 0.0375, 0.0001, 0.1991, 0.3421, 0.0001, 0.0575, 0.0009]\n",
      "1   <=> 1  --  True [0.0011, 0.9373, 0.0175, 0.0069, 0.0017, 0.0027, 0.0076, 0.0123, 0.0085, 0.0045]\n",
      "0   <=> 0  --  True [0.9829, 0.0, 0.0008, 0.0, 0.0, 0.0027, 0.0101, 0.0032, 0.0001, 0.0001]\n",
      "4   <=> 4  --  True [0.0036, 0.0003, 0.0233, 0.0021, 0.9096, 0.0013, 0.0101, 0.0235, 0.0114, 0.0149]\n",
      "1   <=> 1  --  True [0.0002, 0.9681, 0.0069, 0.0032, 0.0005, 0.0008, 0.0009, 0.0109, 0.0051, 0.0034]\n",
      "\n",
      "Accuracy = 0.812\n"
     ]
    }
   ],
   "source": [
    "thetas_10000 = trainMaxEnt(X_norm[:1000], ind_y[:1000], 10000)\n",
    "print(\"\\nAccuracy =\", calculateAcc(thetas_10000, X_test_norm[:1000], y_test[:1000])/len(X_test_norm[:1000]))\n",
    "\n",
    "thetas_20000 = trainMaxEnt(X_norm[:1000], ind_y[:1000], 20000)\n",
    "print(\"\\nAccuracy =\", calculateAcc(thetas_10000, X_test_norm[:1000], y_test[:1000])/len(X_test_norm[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zwiększenie liczby kroków w znaczny sposób wydłuża czas działania algorytmu, ale w małym stopniu (lub wcale) poprawia skuteczność."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(X, y, batch_size):\n",
    "    batches = []\n",
    "    m = X.shape[0]\n",
    "    for i in range(0, m, batch_size):\n",
    "        batches.append((X[i : i+batch_size], y[i : i+batch_size]))\n",
    "    return batches\n",
    "\n",
    "def batch_SGD(h, fJ, fdJ, theta, X, y, alpha=0.01, eps=10**-3, maxSteps=10000, batch_size = 120):\n",
    "    errorCurr = fJ(h, theta, X, y)\n",
    "    errors = [[errorCurr, theta]]\n",
    "    flag = True\n",
    "    while flag:\n",
    "        for batch_x, batch_y in get_batches(X, y, batch_size):\n",
    "            theta = theta - alpha * fdJ(h, theta, batch_x, batch_y)\n",
    "            errorCurr, errorPrev = fJ(h, theta, batch_x, batch_y), errorCurr\n",
    "            if abs(errorPrev - errorCurr) <= eps:\n",
    "                flag = False\n",
    "                break\n",
    "            if len(errors) > maxSteps:\n",
    "                flag = False\n",
    "                break\n",
    "            errors.append([errorCurr, theta])\n",
    "    return theta, errors\n",
    "\n",
    "def batch_trainMaxEnt(X, Y, alpha, batch_size, steps):\n",
    "    n = X.shape[1]\n",
    "    thetas = []\n",
    "    for c in range(Y.shape[1]):\n",
    "        YBi = Y[:,c]\n",
    "        theta = np.matrix(np.random.random(n)).reshape(n,1)\n",
    "        thetaBest, errors = batch_SGD(h, J, dJ, theta, X, YBi, alpha=alpha, eps=10**-4, maxSteps=steps, batch_size=batch_size)\n",
    "        thetas.append(thetaBest)\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.020000\n",
      "steps: 100\n",
      "batchSize: 10\n",
      "7   <=> 7  --  True [0.0333, 0.0124, 0.0268, 0.0431, 0.0542, 0.0298, 0.0188, 0.6745, 0.0341, 0.0731]\n",
      "2   <=> 6  --  False [0.1604, 0.0745, 0.1301, 0.1196, 0.0222, 0.1536, 0.1815, 0.0221, 0.1114, 0.0246]\n",
      "1   <=> 1  --  True [0.037, 0.4057, 0.0783, 0.0761, 0.0412, 0.0597, 0.068, 0.0875, 0.0929, 0.0537]\n",
      "0   <=> 0  --  True [0.5788, 0.0045, 0.0266, 0.0257, 0.027, 0.0552, 0.1384, 0.101, 0.0208, 0.0219]\n",
      "4   <=> 4  --  True [0.0658, 0.0143, 0.0978, 0.049, 0.3767, 0.044, 0.0785, 0.1443, 0.05, 0.0795]\n",
      "1   <=> 1  --  True [0.022, 0.514, 0.0578, 0.0649, 0.0294, 0.0443, 0.0379, 0.0922, 0.0878, 0.0496]\n",
      "Accuracy = 0.955767\n",
      "\n",
      "alpha: 0.020000\n",
      "steps: 100\n",
      "batchSize: 100\n",
      "7   <=> 7  --  True [0.0453, 0.0337, 0.0409, 0.0494, 0.0555, 0.0385, 0.0237, 0.5607, 0.046, 0.1063]\n",
      "2   <=> 2  --  True [0.1108, 0.0801, 0.2087, 0.1712, 0.0147, 0.0934, 0.1981, 0.0141, 0.0903, 0.0187]\n",
      "1   <=> 1  --  True [0.0452, 0.318, 0.1057, 0.0966, 0.0512, 0.069, 0.0774, 0.071, 0.1013, 0.0646]\n",
      "0   <=> 0  --  True [0.6558, 0.013, 0.0368, 0.0319, 0.0149, 0.0396, 0.111, 0.0461, 0.0237, 0.0271]\n",
      "4   <=> 4  --  True [0.075, 0.0297, 0.1208, 0.0473, 0.2768, 0.0461, 0.0868, 0.1083, 0.0783, 0.1309]\n",
      "1   <=> 1  --  True [0.0294, 0.4, 0.0921, 0.0959, 0.0416, 0.0555, 0.0445, 0.0714, 0.1056, 0.064]\n",
      "Accuracy = 0.965383\n",
      "\n",
      "alpha: 0.020000\n",
      "steps: 100\n",
      "batchSize: 1000\n",
      "7   <=> 7  --  True [0.0441, 0.0325, 0.0404, 0.0482, 0.0584, 0.0392, 0.0359, 0.5466, 0.0487, 0.1058]\n",
      "2   <=> 2  --  True [0.101, 0.078, 0.2428, 0.176, 0.017, 0.0993, 0.1484, 0.0147, 0.0943, 0.0283]\n",
      "1   <=> 1  --  True [0.0427, 0.3147, 0.1009, 0.09, 0.0523, 0.0667, 0.0891, 0.0705, 0.1, 0.0731]\n",
      "0   <=> 0  --  True [0.6167, 0.013, 0.0424, 0.0354, 0.0208, 0.0539, 0.1003, 0.0488, 0.029, 0.0395]\n",
      "4   <=> 4  --  True [0.0734, 0.0265, 0.1084, 0.0454, 0.289, 0.0511, 0.093, 0.1029, 0.0781, 0.1322]\n",
      "1   <=> 1  --  True [0.0273, 0.3818, 0.0876, 0.0896, 0.0441, 0.0546, 0.0632, 0.0712, 0.1075, 0.0731]\n",
      "Accuracy = 0.967167\n",
      "\n",
      "alpha: 0.020000\n",
      "steps: 1000\n",
      "batchSize: 10\n",
      "7   <=> 7  --  True [0.002, 0.0001, 0.0008, 0.0016, 0.0017, 0.0006, 0.0012, 0.9864, 0.0008, 0.0048]\n",
      "2   <=> 2  --  True [0.0898, 0.0085, 0.5032, 0.0784, 0.0012, 0.0997, 0.1689, 0.0002, 0.049, 0.0011]\n",
      "1   <=> 1  --  True [0.0114, 0.8938, 0.017, 0.0098, 0.0064, 0.0065, 0.0256, 0.0099, 0.0111, 0.0085]\n",
      "0   <=> 0  --  True [0.6977, 0.0001, 0.0079, 0.0021, 0.0022, 0.0183, 0.2298, 0.0298, 0.0027, 0.0094]\n",
      "4   <=> 4  --  True [0.0496, 0.0005, 0.0589, 0.0035, 0.6038, 0.0078, 0.0648, 0.0528, 0.0482, 0.11]\n",
      "1   <=> 1  --  True [0.0036, 0.9567, 0.0058, 0.0046, 0.0023, 0.0018, 0.0074, 0.0063, 0.0066, 0.0048]\n",
      "Accuracy = 0.974283\n",
      "\n",
      "alpha: 0.020000\n",
      "steps: 1000\n",
      "batchSize: 100\n",
      "7   <=> 7  --  True [0.0167, 0.0162, 0.0108, 0.0234, 0.0118, 0.006, 0.002, 0.8842, 0.0075, 0.0215]\n",
      "2   <=> 2  --  True [0.075, 0.0641, 0.3337, 0.1567, 0.0011, 0.0908, 0.2337, 0.0025, 0.042, 0.0004]\n",
      "1   <=> 1  --  True [0.0419, 0.4481, 0.1077, 0.1351, 0.03, 0.0374, 0.0561, 0.0666, 0.0484, 0.0286]\n",
      "0   <=> 0  --  True [0.8311, 0.0113, 0.0137, 0.0258, 0.0017, 0.0174, 0.0708, 0.024, 0.002, 0.0021]\n",
      "4   <=> 4  --  True [0.0473, 0.0247, 0.0767, 0.0354, 0.5911, 0.0122, 0.0381, 0.0718, 0.0366, 0.0661]\n",
      "1   <=> 1  --  True [0.0226, 0.5553, 0.0815, 0.1336, 0.021, 0.0224, 0.0165, 0.0655, 0.0509, 0.0307]\n",
      "Accuracy = 0.974450\n",
      "\n",
      "alpha: 0.020000\n",
      "steps: 1000\n",
      "batchSize: 1000\n",
      "7   <=> 7  --  True [0.021, 0.0162, 0.0115, 0.0147, 0.024, 0.0189, 0.0178, 0.8115, 0.0117, 0.0526]\n",
      "2   <=> 2  --  True [0.0882, 0.0697, 0.393, 0.1321, 0.0082, 0.0886, 0.1325, 0.0038, 0.0587, 0.0253]\n",
      "1   <=> 1  --  True [0.0489, 0.3814, 0.0847, 0.0402, 0.0484, 0.0789, 0.1079, 0.0603, 0.0606, 0.0886]\n",
      "0   <=> 0  --  True [0.697, 0.0141, 0.0211, 0.003, 0.0131, 0.0571, 0.1083, 0.037, 0.0066, 0.0427]\n",
      "4   <=> 4  --  True [0.0704, 0.0264, 0.095, 0.0054, 0.3833, 0.0495, 0.0927, 0.0899, 0.0557, 0.1317]\n",
      "1   <=> 1  --  True [0.0309, 0.4675, 0.0631, 0.04, 0.0391, 0.0647, 0.0774, 0.0616, 0.0662, 0.0895]\n",
      "Accuracy = 0.965250\n",
      "\n",
      "alpha: 0.020000\n",
      "steps: 10000\n",
      "batchSize: 10\n",
      "7   <=> 7  --  True [0.002, 0.0001, 0.0008, 0.0016, 0.0017, 0.0006, 0.0012, 0.9866, 0.0007, 0.0048]\n",
      "2   <=> 2  --  True [0.0923, 0.0088, 0.5176, 0.0807, 0.0013, 0.1026, 0.1737, 0.0002, 0.0216, 0.0011]\n",
      "1   <=> 1  --  True [0.0114, 0.8972, 0.0171, 0.0098, 0.0064, 0.0066, 0.0257, 0.01, 0.0073, 0.0085]\n",
      "0   <=> 0  --  True [0.699, 0.0001, 0.0079, 0.0021, 0.0022, 0.0183, 0.2302, 0.0299, 0.0009, 0.0094]\n",
      "4   <=> 4  --  True [0.0511, 0.0006, 0.0607, 0.0036, 0.6225, 0.0081, 0.0668, 0.0545, 0.0188, 0.1134]\n",
      "1   <=> 1  --  True [0.0036, 0.9582, 0.0059, 0.0046, 0.0023, 0.0018, 0.0075, 0.0063, 0.0051, 0.0048]\n",
      "Accuracy = 0.974867\n",
      "\n",
      "alpha: 0.020000\n",
      "steps: 10000\n",
      "batchSize: 100\n",
      "7   <=> 7  --  True [0.0167, 0.0162, 0.0108, 0.0235, 0.0118, 0.006, 0.002, 0.8876, 0.0075, 0.0178]\n",
      "2   <=> 2  --  True [0.075, 0.0641, 0.3337, 0.1567, 0.0011, 0.0908, 0.2337, 0.0025, 0.042, 0.0003]\n",
      "1   <=> 1  --  True [0.042, 0.4492, 0.1079, 0.1354, 0.0301, 0.0375, 0.0563, 0.0668, 0.0485, 0.0263]\n",
      "0   <=> 0  --  True [0.8316, 0.0113, 0.0137, 0.0259, 0.0017, 0.0174, 0.0709, 0.0241, 0.002, 0.0015]\n",
      "4   <=> 4  --  True [0.0479, 0.025, 0.0777, 0.0358, 0.5986, 0.0124, 0.0386, 0.0727, 0.0371, 0.0542]\n",
      "1   <=> 1  --  True [0.0227, 0.5569, 0.0817, 0.134, 0.0211, 0.0225, 0.0165, 0.0657, 0.051, 0.0278]\n",
      "Accuracy = 0.974467\n",
      "\n",
      "alpha: 0.020000\n",
      "steps: 10000\n",
      "batchSize: 1000\n",
      "7   <=> 7  --  True [0.021, 0.0162, 0.0115, 0.0147, 0.024, 0.0189, 0.0178, 0.8115, 0.0117, 0.0526]\n",
      "2   <=> 2  --  True [0.0882, 0.0697, 0.393, 0.1321, 0.0082, 0.0886, 0.1325, 0.0038, 0.0587, 0.0253]\n",
      "1   <=> 1  --  True [0.0489, 0.3814, 0.0847, 0.0402, 0.0484, 0.0789, 0.1079, 0.0603, 0.0606, 0.0886]\n",
      "0   <=> 0  --  True [0.697, 0.0141, 0.0211, 0.003, 0.0131, 0.0571, 0.1083, 0.037, 0.0066, 0.0427]\n",
      "4   <=> 4  --  True [0.0704, 0.0264, 0.095, 0.0054, 0.3833, 0.0495, 0.0927, 0.0899, 0.0557, 0.1317]\n",
      "1   <=> 1  --  True [0.0309, 0.4675, 0.0631, 0.04, 0.0391, 0.0647, 0.0774, 0.0616, 0.0662, 0.0895]\n",
      "Accuracy = 0.965250\n",
      "\n",
      "alpha: 0.010000\n",
      "steps: 100\n",
      "batchSize: 10\n",
      "7   <=> 7  --  True [0.0676, 0.0355, 0.0575, 0.0735, 0.0894, 0.0606, 0.0483, 0.3956, 0.0665, 0.1054]\n",
      "2   <=> 0  --  False [0.1496, 0.0883, 0.1239, 0.1164, 0.0442, 0.1279, 0.1455, 0.0454, 0.1126, 0.0461]\n",
      "1   <=> 1  --  True [0.0605, 0.244, 0.0949, 0.0916, 0.0637, 0.0794, 0.0848, 0.0998, 0.1066, 0.0745]\n",
      "0   <=> 0  --  True [0.3801, 0.0175, 0.0549, 0.0523, 0.0557, 0.0786, 0.1407, 0.1258, 0.0467, 0.0476]\n",
      "4   <=> 4  --  True [0.0912, 0.0326, 0.1064, 0.07, 0.2308, 0.0661, 0.095, 0.1418, 0.0708, 0.0951]\n",
      "1   <=> 1  --  True [0.0469, 0.298, 0.0847, 0.0878, 0.0551, 0.0701, 0.0639, 0.1087, 0.11, 0.0747]\n",
      "Accuracy = 0.951400\n",
      "\n",
      "alpha: 0.010000\n",
      "steps: 100\n",
      "batchSize: 100\n",
      "7   <=> 7  --  True [0.0763, 0.0441, 0.1167, 0.0758, 0.0797, 0.0602, 0.0503, 0.3062, 0.0717, 0.119]\n",
      "2   <=> 2  --  True [0.1266, 0.0843, 0.1735, 0.1547, 0.0344, 0.091, 0.1612, 0.034, 0.1005, 0.0399]\n",
      "1   <=> 1  --  True [0.0597, 0.2545, 0.1312, 0.0948, 0.0616, 0.0721, 0.0813, 0.0762, 0.0966, 0.0721]\n",
      "0   <=> 0  --  True [0.4194, 0.0176, 0.1327, 0.0596, 0.0346, 0.053, 0.1194, 0.0676, 0.0464, 0.0496]\n",
      "4   <=> 4  --  True [0.0988, 0.032, 0.1409, 0.0692, 0.1806, 0.0617, 0.0984, 0.1098, 0.0875, 0.121]\n",
      "1   <=> 1  --  True [0.0457, 0.3071, 0.1378, 0.0937, 0.0531, 0.0614, 0.0583, 0.0751, 0.0976, 0.0702]\n",
      "Accuracy = 0.947683\n",
      "\n",
      "alpha: 0.010000\n",
      "steps: 100\n",
      "batchSize: 1000\n",
      "7   <=> 7  --  True [0.0785, 0.0479, 0.0701, 0.0781, 0.0873, 0.066, 0.0536, 0.3139, 0.0795, 0.125]\n",
      "2   <=> 2  --  True [0.1163, 0.0849, 0.173, 0.1524, 0.0369, 0.0956, 0.1517, 0.034, 0.1027, 0.0524]\n",
      "1   <=> 1  --  True [0.0603, 0.2576, 0.1004, 0.0947, 0.0656, 0.0751, 0.0832, 0.0788, 0.1013, 0.0831]\n",
      "0   <=> 0  --  True [0.4062, 0.0205, 0.0693, 0.0649, 0.0442, 0.0697, 0.1302, 0.0719, 0.0559, 0.0672]\n",
      "4   <=> 4  --  True [0.0989, 0.0328, 0.1119, 0.0689, 0.1905, 0.0689, 0.1027, 0.1087, 0.0913, 0.1255]\n",
      "1   <=> 1  --  True [0.0466, 0.3087, 0.0932, 0.0952, 0.059, 0.0662, 0.062, 0.0793, 0.1065, 0.0835]\n",
      "Accuracy = 0.963517\n",
      "\n",
      "alpha: 0.010000\n",
      "steps: 1000\n",
      "batchSize: 10\n",
      "7   <=> 7  --  True [0.0045, 0.0017, 0.0031, 0.0123, 0.0036, 0.0029, 0.0007, 0.9543, 0.0036, 0.0133]\n",
      "2   <=> 2  --  True [0.0709, 0.0304, 0.371, 0.1146, 0.0005, 0.0813, 0.2906, 0.0005, 0.0389, 0.0012]\n",
      "1   <=> 1  --  True [0.0098, 0.7257, 0.0441, 0.0795, 0.0128, 0.0216, 0.0292, 0.0231, 0.0345, 0.0196]\n",
      "0   <=> 0  --  True [0.9498, 0.0003, 0.0019, 0.0099, 0.0002, 0.0041, 0.0273, 0.0043, 0.0008, 0.0013]\n",
      "4   <=> 4  --  True [0.0264, 0.0044, 0.0722, 0.0429, 0.62, 0.011, 0.0385, 0.0542, 0.04, 0.0903]\n",
      "1   <=> 1  --  True [0.0031, 0.842, 0.0213, 0.0572, 0.0059, 0.0094, 0.0056, 0.0165, 0.025, 0.0141]\n",
      "Accuracy = 0.973983\n",
      "\n",
      "alpha: 0.010000\n",
      "steps: 1000\n",
      "batchSize: 100\n",
      "7   <=> 7  --  True [0.0046, 0.0014, 0.0168, 0.0059, 0.004, 0.0024, 0.0046, 0.9372, 0.0038, 0.0194]\n",
      "2   <=> 3  --  False [0.0911, 0.0488, 0.2016, 0.2248, 0.0014, 0.1281, 0.2071, 0.0009, 0.0705, 0.0258]\n",
      "1   <=> 1  --  True [0.0115, 0.7041, 0.0919, 0.0318, 0.0119, 0.0158, 0.0464, 0.0205, 0.0261, 0.0398]\n",
      "0   <=> 0  --  True [0.8164, 0.0005, 0.0682, 0.0057, 0.001, 0.0133, 0.0627, 0.0105, 0.0025, 0.0191]\n",
      "4   <=> 4  --  True [0.0313, 0.003, 0.1063, 0.0119, 0.5814, 0.0118, 0.066, 0.0492, 0.0409, 0.0981]\n",
      "1   <=> 1  --  True [0.0039, 0.8053, 0.071, 0.0221, 0.0061, 0.007, 0.0203, 0.0152, 0.0206, 0.0285]\n",
      "Accuracy = 0.964583\n",
      "\n",
      "alpha: 0.010000\n",
      "steps: 1000\n",
      "batchSize: 1000\n",
      "7   <=> 7  --  True [0.02, 0.0077, 0.0163, 0.0134, 0.0264, 0.0157, 0.005, 0.8398, 0.0162, 0.0396]\n",
      "2   <=> 2  --  True [0.0953, 0.0594, 0.2222, 0.1695, 0.0264, 0.0915, 0.208, 0.0031, 0.0777, 0.0469]\n",
      "1   <=> 1  --  True [0.0402, 0.4972, 0.0806, 0.0432, 0.0549, 0.0529, 0.0462, 0.0388, 0.068, 0.0778]\n",
      "0   <=> 0  --  True [0.5802, 0.0051, 0.046, 0.0111, 0.0339, 0.0612, 0.1431, 0.0374, 0.021, 0.0611]\n",
      "4   <=> 4  --  True [0.0968, 0.0143, 0.1317, 0.0188, 0.2509, 0.0602, 0.088, 0.1081, 0.0857, 0.1456]\n",
      "1   <=> 1  --  True [0.024, 0.6103, 0.0611, 0.0368, 0.0428, 0.0378, 0.0182, 0.0348, 0.0649, 0.0693]\n",
      "Accuracy = 0.963883\n",
      "\n",
      "alpha: 0.010000\n",
      "steps: 10000\n",
      "batchSize: 10\n",
      "7   <=> 7  --  True [0.001, 0.0004, 0.0007, 0.0028, 0.0001, 0.0005, 0.0002, 0.9922, 0.0008, 0.0013]\n",
      "2   <=> 2  --  True [0.0642, 0.0275, 0.4055, 0.1038, 0.0, 0.1005, 0.2631, 0.0, 0.0352, 0.0002]\n",
      "1   <=> 1  --  True [0.0102, 0.7504, 0.0374, 0.0822, 0.0049, 0.0193, 0.0302, 0.0176, 0.0357, 0.0121]\n",
      "0   <=> 0  --  True [0.953, 0.0003, 0.0022, 0.01, 0.0, 0.0041, 0.0274, 0.0018, 0.0008, 0.0004]\n",
      "4   <=> 4  --  True [0.0211, 0.0035, 0.0692, 0.0344, 0.7335, 0.007, 0.0309, 0.0225, 0.032, 0.0458]\n",
      "1   <=> 1  --  True [0.0031, 0.8558, 0.0173, 0.0581, 0.0019, 0.0083, 0.0057, 0.0145, 0.0254, 0.0097]\n",
      "Accuracy = 0.976250\n",
      "\n",
      "alpha: 0.010000\n",
      "steps: 10000\n",
      "batchSize: 100\n",
      "7   <=> 7  --  True [0.0016, 0.0005, 0.0057, 0.002, 0.0014, 0.0007, 0.0016, 0.9788, 0.0012, 0.0066]\n",
      "2   <=> 3  --  False [0.0901, 0.0482, 0.1994, 0.2224, 0.0014, 0.1349, 0.2048, 0.0001, 0.0732, 0.0255]\n",
      "1   <=> 1  --  True [0.0116, 0.7107, 0.0928, 0.0321, 0.0121, 0.0148, 0.0469, 0.0134, 0.0255, 0.0402]\n",
      "0   <=> 0  --  True [0.823, 0.0005, 0.0688, 0.0057, 0.001, 0.0121, 0.0632, 0.0039, 0.0024, 0.0193]\n",
      "4   <=> 4  --  True [0.0321, 0.0031, 0.1088, 0.0122, 0.5952, 0.0109, 0.0676, 0.0278, 0.0418, 0.1005]\n",
      "1   <=> 1  --  True [0.0039, 0.81, 0.0714, 0.0222, 0.0061, 0.0063, 0.0204, 0.0106, 0.0202, 0.0286]\n",
      "Accuracy = 0.965483\n",
      "\n",
      "alpha: 0.010000\n",
      "steps: 10000\n",
      "batchSize: 1000\n",
      "7   <=> 7  --  True [0.02, 0.0077, 0.0163, 0.0134, 0.0264, 0.0157, 0.005, 0.8398, 0.0162, 0.0396]\n",
      "2   <=> 2  --  True [0.0953, 0.0594, 0.2222, 0.1695, 0.0264, 0.0915, 0.208, 0.0031, 0.0777, 0.0469]\n",
      "1   <=> 1  --  True [0.0402, 0.4972, 0.0806, 0.0432, 0.0549, 0.0529, 0.0462, 0.0388, 0.068, 0.0778]\n",
      "0   <=> 0  --  True [0.5802, 0.0051, 0.046, 0.0111, 0.0339, 0.0612, 0.1431, 0.0374, 0.021, 0.0611]\n",
      "4   <=> 4  --  True [0.0968, 0.0143, 0.1317, 0.0188, 0.2509, 0.0602, 0.088, 0.1081, 0.0857, 0.1456]\n",
      "1   <=> 1  --  True [0.024, 0.6103, 0.0611, 0.0368, 0.0428, 0.0378, 0.0182, 0.0348, 0.0649, 0.0693]\n",
      "Accuracy = 0.963883\n",
      "\n",
      "alpha: 0.100000\n",
      "steps: 100\n",
      "batchSize: 10\n",
      "7   <=> 7  --  True [0.0017, 0.0001, 0.0012, 0.0043, 0.002, 0.0008, 0.0002, 0.983, 0.0016, 0.0049]\n",
      "2   <=> 6  --  False [0.1414, 0.0212, 0.1076, 0.0835, 0.0012, 0.18, 0.3718, 0.0013, 0.0891, 0.0029]\n",
      "1   <=> 1  --  True [0.0041, 0.8579, 0.0197, 0.0199, 0.0046, 0.0082, 0.0198, 0.035, 0.021, 0.0098]\n",
      "0   <=> 0  --  True [0.9327, 0.0, 0.0014, 0.0008, 0.0005, 0.003, 0.0414, 0.0186, 0.0008, 0.0008]\n",
      "4   <=> 4  --  True [0.0105, 0.0008, 0.0388, 0.0081, 0.8324, 0.0041, 0.0201, 0.0539, 0.0128, 0.0184]\n",
      "1   <=> 1  --  True [0.001, 0.9225, 0.0068, 0.0109, 0.0015, 0.0029, 0.0036, 0.0329, 0.0118, 0.0062]\n",
      "Accuracy = 0.964533\n",
      "\n",
      "alpha: 0.100000\n",
      "steps: 100\n",
      "batchSize: 100\n",
      "7   <=> 7  --  True [0.0042, 0.0005, 0.0029, 0.0054, 0.0032, 0.0027, 0.0006, 0.9634, 0.004, 0.013]\n",
      "2   <=> 2  --  True [0.0681, 0.0139, 0.3796, 0.1094, 0.0005, 0.0894, 0.2818, 0.0005, 0.0554, 0.0014]\n",
      "1   <=> 1  --  True [0.0078, 0.8789, 0.0222, 0.0184, 0.0063, 0.011, 0.014, 0.0118, 0.0195, 0.0103]\n",
      "0   <=> 0  --  True [0.8918, 0.0001, 0.0053, 0.0029, 0.0004, 0.0128, 0.0648, 0.0139, 0.0035, 0.0044]\n",
      "4   <=> 4  --  True [0.0318, 0.0011, 0.0747, 0.0079, 0.6145, 0.0116, 0.0365, 0.0604, 0.0582, 0.1033]\n",
      "1   <=> 1  --  True [0.0021, 0.9471, 0.0084, 0.0098, 0.0023, 0.0038, 0.002, 0.0067, 0.0119, 0.0059]\n",
      "Accuracy = 0.974300\n",
      "\n",
      "alpha: 0.100000\n",
      "steps: 100\n",
      "batchSize: 1000\n",
      "7   <=> 7  --  True [0.0031, 0.0073, 0.0027, 0.0054, 0.003, 0.0023, 0.0005, 0.9574, 0.0036, 0.0145]\n",
      "2   <=> 2  --  True [0.0461, 0.0584, 0.4714, 0.1036, 0.0005, 0.0711, 0.2081, 0.0005, 0.0391, 0.0012]\n",
      "1   <=> 1  --  True [0.0185, 0.4607, 0.0973, 0.0788, 0.0321, 0.0492, 0.065, 0.0645, 0.0812, 0.0528]\n",
      "0   <=> 0  --  True [0.9479, 0.0064, 0.0028, 0.0015, 0.0003, 0.0067, 0.0256, 0.0054, 0.0013, 0.0022]\n",
      "4   <=> 4  --  True [0.0194, 0.033, 0.0587, 0.0075, 0.6406, 0.0123, 0.0327, 0.0522, 0.0428, 0.1008]\n",
      "1   <=> 1  --  True [0.0073, 0.5614, 0.0659, 0.0783, 0.0226, 0.031, 0.0177, 0.0684, 0.0912, 0.0562]\n",
      "Accuracy = 0.975300\n",
      "\n",
      "alpha: 0.100000\n",
      "steps: 1000\n",
      "batchSize: 10\n",
      "7   <=> 7  --  True [0.0006, 0.0, 0.0005, 0.0021, 0.0001, 0.0013, 0.0, 0.9949, 0.0003, 0.0002]\n",
      "2   <=> 2  --  True [0.0451, 0.0017, 0.7871, 0.028, 0.0, 0.0502, 0.0797, 0.0002, 0.008, 0.0]\n",
      "1   <=> 1  --  True [0.0004, 0.971, 0.0052, 0.0033, 0.0013, 0.0029, 0.0015, 0.0106, 0.0028, 0.0009]\n",
      "0   <=> 0  --  True [0.9973, 0.0, 0.0, 0.0, 0.0, 0.0007, 0.0003, 0.0016, 0.0, 0.0]\n",
      "4   <=> 4  --  True [0.0008, 0.0, 0.003, 0.0002, 0.9724, 0.001, 0.0007, 0.011, 0.0074, 0.0034]\n",
      "1   <=> 1  --  True [0.0, 0.9871, 0.0014, 0.0014, 0.0003, 0.0008, 0.0, 0.0062, 0.0021, 0.0005]\n",
      "Accuracy = 0.977667\n",
      "\n",
      "alpha: 0.100000\n",
      "steps: 1000\n",
      "batchSize: 100\n",
      "7   <=> 7  --  True [0.0004, 0.0, 0.0002, 0.0004, 0.0, 0.0, 0.0, 0.9987, 0.0001, 0.0001]\n",
      "2   <=> 2  --  True [0.0423, 0.0033, 0.7019, 0.0447, 0.0, 0.0599, 0.139, 0.0, 0.0089, 0.0]\n",
      "1   <=> 1  --  True [0.0048, 0.9645, 0.0103, 0.0054, 0.0009, 0.0016, 0.0043, 0.0039, 0.0025, 0.0017]\n",
      "0   <=> 0  --  True [0.9763, 0.0, 0.0037, 0.0005, 0.0, 0.0036, 0.0138, 0.0017, 0.0003, 0.0002]\n",
      "4   <=> 4  --  True [0.0167, 0.0002, 0.0261, 0.0008, 0.9235, 0.0006, 0.0054, 0.0076, 0.0068, 0.0123]\n",
      "1   <=> 1  --  True [0.0011, 0.9863, 0.0032, 0.0026, 0.0002, 0.0003, 0.0003, 0.0028, 0.0019, 0.0013]\n",
      "Accuracy = 0.980983\n",
      "\n",
      "alpha: 0.100000\n",
      "steps: 1000\n",
      "batchSize: 1000\n",
      "7   <=> 7  --  True [0.0004, 0.0016, 0.0003, 0.0011, 0.0003, 0.0001, 0.0, 0.993, 0.0001, 0.0031]\n",
      "2   <=> 2  --  True [0.0191, 0.0255, 0.7958, 0.0392, 0.0001, 0.0373, 0.0762, 0.0, 0.0062, 0.0005]\n",
      "1   <=> 1  --  True [0.0072, 0.6097, 0.0596, 0.0789, 0.0286, 0.0271, 0.0418, 0.0505, 0.0267, 0.0699]\n",
      "0   <=> 0  --  True [0.9933, 0.0022, 0.0002, 0.0002, 0.0, 0.0007, 0.0019, 0.0005, 0.0001, 0.0008]\n",
      "4   <=> 4  --  True [0.0073, 0.0353, 0.0227, 0.0042, 0.7687, 0.0032, 0.0103, 0.0259, 0.0144, 0.1079]\n",
      "1   <=> 1  --  True [0.002, 0.6896, 0.0286, 0.0745, 0.0174, 0.0109, 0.0049, 0.0578, 0.0453, 0.069]\n",
      "Accuracy = 0.979783\n",
      "\n",
      "alpha: 0.100000\n",
      "steps: 10000\n",
      "batchSize: 10\n",
      "7   <=> 7  --  True [0.0006, 0.0, 0.0003, 0.0021, 0.0001, 0.0013, 0.0, 0.9951, 0.0002, 0.0002]\n",
      "2   <=> 2  --  True [0.0356, 0.0014, 0.6736, 0.0221, 0.0, 0.0396, 0.2257, 0.0002, 0.002, 0.0]\n",
      "1   <=> 1  --  True [0.0004, 0.9717, 0.0046, 0.0033, 0.0013, 0.0029, 0.0023, 0.0106, 0.0019, 0.0009]\n",
      "0   <=> 0  --  True [0.9969, 0.0, 0.0, 0.0, 0.0, 0.0007, 0.0008, 0.0016, 0.0, 0.0]\n",
      "4   <=> 4  --  True [0.0008, 0.0, 0.0014, 0.0002, 0.9788, 0.001, 0.0009, 0.0111, 0.0024, 0.0035]\n",
      "1   <=> 1  --  True [0.0, 0.9884, 0.001, 0.0014, 0.0003, 0.0008, 0.0001, 0.0063, 0.0012, 0.0005]\n",
      "Accuracy = 0.978100\n",
      "\n",
      "alpha: 0.100000\n",
      "steps: 10000\n",
      "batchSize: 100\n",
      "7   <=> 7  --  True [0.0003, 0.0, 0.0002, 0.0003, 0.0, 0.0, 0.0, 0.9991, 0.0, 0.0001]\n",
      "2   <=> 2  --  True [0.0423, 0.0033, 0.7019, 0.0447, 0.0, 0.0599, 0.139, 0.0, 0.0089, 0.0]\n",
      "1   <=> 1  --  True [0.0048, 0.9659, 0.0103, 0.0054, 0.0008, 0.0016, 0.0043, 0.0031, 0.0025, 0.0013]\n",
      "0   <=> 0  --  True [0.977, 0.0, 0.0037, 0.0005, 0.0, 0.0036, 0.0138, 0.0009, 0.0003, 0.0003]\n",
      "4   <=> 4  --  True [0.0096, 0.0001, 0.0149, 0.0004, 0.9562, 0.0004, 0.0031, 0.0027, 0.0039, 0.0088]\n",
      "1   <=> 1  --  True [0.0011, 0.9869, 0.0032, 0.0026, 0.0002, 0.0003, 0.0003, 0.0025, 0.0019, 0.0011]\n",
      "Accuracy = 0.981150\n",
      "\n",
      "alpha: 0.100000\n",
      "steps: 10000\n",
      "batchSize: 1000\n",
      "7   <=> 7  --  True [0.0004, 0.0016, 0.0003, 0.0011, 0.0003, 0.0001, 0.0, 0.993, 0.0001, 0.0031]\n",
      "2   <=> 2  --  True [0.0191, 0.0255, 0.7958, 0.0392, 0.0001, 0.0373, 0.0762, 0.0, 0.0062, 0.0005]\n",
      "1   <=> 1  --  True [0.0072, 0.6097, 0.0596, 0.0789, 0.0286, 0.0271, 0.0418, 0.0505, 0.0267, 0.0699]\n",
      "0   <=> 0  --  True [0.9933, 0.0022, 0.0002, 0.0002, 0.0, 0.0007, 0.0019, 0.0005, 0.0001, 0.0008]\n",
      "4   <=> 4  --  True [0.0073, 0.0353, 0.0227, 0.0042, 0.7687, 0.0032, 0.0103, 0.0259, 0.0144, 0.1079]\n",
      "1   <=> 1  --  True [0.002, 0.6896, 0.0286, 0.0745, 0.0174, 0.0109, 0.0049, 0.0578, 0.0453, 0.069]\n",
      "Accuracy = 0.979783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.02, 0.01, 0.1]\n",
    "steps = [100, 1000, 10000]\n",
    "batchSizes = [10, 100, 1000]\n",
    "\n",
    "for alpha in alphas:\n",
    "    for step in steps: \n",
    "        for batchSize in batchSizes:\n",
    "            print('alpha: %f' % alpha)\n",
    "            print('steps: %d' % step)\n",
    "            print('batchSize: %d' % batchSize)\n",
    "            batch_theta = batch_trainMaxEnt(X_norm, ind_y, alpha, batchSize, step)\n",
    "            print(\"Accuracy = %f\\n\" % (calculateAcc(batch_theta, X_test_norm, y_test)/len(X_test_norm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uzyskano wyniki z przedziału 0.947683 - 0.981150. \n",
    "\n",
    "Dla porównania, wybieram dane z steps=100 i batchSize=10.\n",
    "Wówczas, dla alfy równej 0.02 otrzymujemy wartość 0.955767, dla 0.01 - 0.951400, natomiast dla 0.1 - 0.964533. Widzimy, że najlepsze wyniki daje wartość 0.1\n",
    "\n",
    "Przy ustalonych parametrach alfa=0.01 i batchSize=100 otrzymujemy accurancy 0.947683 dla 100 kroków, 0.964583 dla 1000 kroków oraz 0.965483 dla 10000 kroków. Jak widać, po osiągnięciu pewnego punktu zwiększanie liczby kroków nie wpływa na wynik.\n",
    "\n",
    "Przy ustalonych parametrach alfa=0.01 i maxSteps=1000 otrzymalismy accurancy 0.973983 dla batchSize=10, 0.964583 dla batchSize=100 oraz 0.963883 dla batchSize=1000. Jak widać, im mniejsza wartość tego parametru, tym lepiej.\n",
    "\n",
    "Podsumowując, największą różnice obserwujemy przy zmianie parametru batchSize, najmniejszą - maxSteps. Najłatwiej jest ustalić parametr maksymalnej liczby kroków właśnie, wystarczy przyjąć np. maxSteps = 1000. Cały problem polega na odpowiednim dostrojeniu ze sobą parametrów alfa i batchSize. Można zauważyć pewną prawidłowość: dla stosunkowo dużej wartości alfa lepsze wyniki uzyskamy dobierając większe batchSize, natomiast dla małej alfy lepiej dobrać mały batchSize."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
